# -*- coding: utf-8 -*-
"""final_tasks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vF7tpwYbcaOE3dQo_RbaiwMyuSeS7G1U

# Import package
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, roc_auc_score, auc
from sklearn.model_selection import cross_val_score

"""# Load dataset"""

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Final Tasks/loan_data_2007_2014.csv")

"""#Exploring data"""

df.info()

df.describe()

df.head()

"""##### 1. Check duplicate data"""

# There is no duplicate data in this dataset.
df.duplicated()

"""# Defining Label"""

# Check target data (loan_status)
df.loan_status.value_counts()

#define values for bad and good loans
good =  ['Current', 'Fully Paid', 'In Grace Period', 'Does not meet the credit policy. Status:Fully Paid']

df['loan_ending'] = np.where(df['loan_status'].isin(good), 'good', 'bad')

# Plot good and bad loans balance
plt.title('Good and Bad Loans Balance')
sns.barplot(x=df.loan_ending.value_counts().index,y=df.loan_ending.value_counts().values)

"""# Data Leakage
##### Data leakage is the unauthorized transmission of data from within an organization to an external destination or recipient. This is the data that we won't get when we use the model in deployment.

##### So, those columns that contain Data Leakage will be drop and only keep the column with data that can be obtained before the loan is invested in.

##### Columns related to the current status of the loan (after it is issued): 'issue_d', 'loan_status', 'pymnt_plan', 'out_prncp', 'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d'
"""

data_leakage = ['issue_d', 'loan_status', 'pymnt_plan', 'out_prncp', 'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d']
df.drop(columns=data_leakage, axis=1, inplace=True)

"""# Feature Engineering
##### Change the format to match the correct format. For example, change date format
1. **Term** is a number of payment on the loan. Change term loan from categorical dtype (36 months) to int (36).
"""

df['term']

df['term'] = pd.to_numeric(df['term'].str.replace(' months', ''))
df['term']

"""##### 2. **emp_length** is employment lenght in years. Change the value to possible value (0-10)."""

df['emp_length'].unique()

emp_change = {
    '< 1 year' : '0',
    '1 year' : '1',
    '2 years' : '2',
    '3 years' : '3',
    '4 years' : '4',
    '5 years' : '5',
    '6 years' : '6',
    '7 years' : '7',
    '8 years' : '8',
    '9 years' : '9',
    '10+ years' : '10'
}

df['emp_length'] = df['emp_length'].map(emp_change).fillna('0').astype(int)
df['emp_length'].unique()

"""##### **3. earliest_cr_line** is the month the borrower's earliest reported credit line was opened"""

df['earliest_cr_line']

df['earliest_cr_line_date'] = pd.to_datetime(df['earliest_cr_line'], format = '%b-%y')

df['mths_since_earliest_cr_line'] = round(pd.to_numeric((pd.to_datetime('2017-12-01') - df['earliest_cr_line_date']) / np.timedelta64(1, 'M')))

df.loc[: , ['earliest_cr_line', 'earliest_cr_line_date', 'mths_since_earliest_cr_line']][df['mths_since_earliest_cr_line'] < 0]

df.drop(columns=['earliest_cr_line_date' ,'mths_since_earliest_cr_line', 'earliest_cr_line'], inplace = True)

"""##### **4. last_credit_pull_d** is the month the borrower's earliest reported credit line was opened"""

df['last_credit_pull_d']

df['last_pull_credit_d_date'] = pd.to_datetime(df['last_credit_pull_d'], format = '%b-%y')

df['math_since_last_pull_credit_d'] = round(pd.to_numeric((pd.to_datetime('2017-12-01') - df['last_pull_credit_d_date']) / np.timedelta64(1, 'M')))

df['math_since_last_pull_credit_d'].describe()

# Drop column last_credit_pull_d that we dont use it anymore
df.drop(columns=['last_credit_pull_d'], axis=1, inplace=True)

"""# Feature Selection
###### Feature Selection is select the features that are needed and drop the features that are not needed (which will later affect the model).

##### 1. Drop columns that have > **50% missing value**
"""

missing_value = df.isnull().mean()
missing_value[missing_value>0.5].index

df.drop(['desc', 'mths_since_last_delinq', 'mths_since_last_record',
       'mths_since_last_major_derog', 'annual_inc_joint', 'dti_joint',
       'verification_status_joint', 'open_acc_6m', 'open_il_6m', 'open_il_12m',
       'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util',
       'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'inq_fi',
       'total_cu_tl', 'inq_last_12m'], axis=1, inplace=True)

"""##### 2. A column that has only **one unique value**"""

df.nunique()[df.nunique() == 1].index

df.drop(['policy_code', 'application_type'], axis=1, inplace=True)

"""##### 3. Drop **identifier columns** that can't be used in building model (id, member_id, title, emp_title, url, zip_code), column **'Unnamed:0'** that a copy of an index, and **sub_grade** columns bcs it contaion same information with column grade."""

df.drop(['id', 'member_id', 'title', 'emp_title', 'url', 'zip_code', 'Unnamed: 0', 'sub_grade'], axis=1, inplace=True)

"""##### 4. Drop 'loan_amnt','funded_amnt','funded_amnt_inv' that have **similar data (columns)**"""

df[['loan_amnt','funded_amnt','funded_amnt_inv']].describe()

# we can see to in the plot of correlation among features too

plt.figure(figsize=(24,24))
sns.heatmap(df.corr(), annot=True, annot_kws={'size':14})

# Based on these results, the three columns have similar data, so we can drop 2 columns.

df.drop(columns=['funded_amnt', 'funded_amnt_inv'], axis=1, inplace=True)

"""# Handling Missing Value"""

df.isnull().sum()

# 'tot_coll_amt', 'tot_cur_bal', 'total_rev_hi_lim' has 15% missing data. Lets check it

total=['tot_coll_amt', 'tot_cur_bal', 'total_rev_hi_lim']
df[total].head(10)

# Drop all rows that contaion missing value
df.dropna(subset=['tot_coll_amt', 'tot_cur_bal', 'total_rev_hi_lim'], inplace=True)
# Reset index
df.reset_index(drop=True, inplace=True)

# Check again NaN value
nan_count = df.isnull().sum()
nan_columns = nan_count[nan_count > 0].index

# Drop all rows that contaion missing value
df.dropna(subset=['revol_util', 'last_pull_credit_d_date', 'math_since_last_pull_credit_d'], inplace=True)
df.reset_index(drop=True, inplace=True)

"""# Encoding"""

cols = [col for col in df.select_dtypes(include='object').columns.tolist()]
onehot = pd.get_dummies(df[cols], drop_first=True)
onehot

"""# Standardization
##### Standaridized all numeric columns with StandardScaler
"""

num = [col for col in df.columns.tolist() if col not in cols + ['loan_ending'] and df[col].dtype != 'datetime64[ns]']
standard = StandardScaler()
standard_cols = pd.DataFrame(standard.fit_transform(df[num]), columns=num)
standard_cols

"""# Final Data"""

final_data = pd.concat([onehot, standard_cols, df[['loan_ending']]], axis=1)
final_data.head()

"""# Splitting Dataset
##### The data will be split into 80% for training and 20% fro test.
"""

x = final_data.drop('loan_ending', axis=1)
y = final_data['loan_ending']

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)

x_train.shape, x_test.shape

plt.title('Good and Bad Loans Balance')
sns.barplot(x=final_data.loan_ending.value_counts().index,y=final_data.loan_ending.value_counts().values)

y_train.value_counts()

"""# RandomForest Classified"""

# training with test dataset
random_forest = RandomForestClassifier(max_depth=10, n_estimators=20)
random_forest.fit(x_train, y_train)

#predicting
y_pred_random_forest = random_forest.predict(x_test)

#classification report
target_names = ['bad loan', 'good loan']
print('Classification_Report:')
print(classification_report(y_test, y_pred_random_forest, digits=4, target_names = target_names))

# Create a confusion matrix
cm = confusion_matrix(y_test, y_pred_random_forest)

# Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=['bad loan', 'good loan'], yticklabels=['bad loan', 'good loan'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Random Forest Classifier')
plt.show()

from sklearn.preprocessing import LabelBinarizer

random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)
random_forest_model.fit(x_train, y_train)

# use LabelBinarizer for change label to numerik
label_binarizer = LabelBinarizer()
y_test_numeric = label_binarizer.fit_transform(y_test)
y_probs = random_forest_model.predict_proba(x_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test_numeric, y_probs)
roc_auc = auc(fpr, tpr)

# Print ROC AUC score
print('ROC AUC Score:', roc_auc)

# Plot ROC Curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()

# Analisis terhadap false negatives
false_negatives = y_test[(y_test == 'bad loan') & (y_pred_random_forest == 'good loan')]
false_negatives_data = x_test.loc[false_negatives.index]
print(false_negatives_data.describe())

cv_scores = cross_val_score(random_forest_model, x, y, cv=5)
print("Cross-Validation Scores:", cv_scores)
print("Mean CV Score:", np.mean(cv_scores))

"""##### Based on these result, the model shows excellent performance based on a high level of accuracy in precision, recall, and f1-score for both classes (bad_loan and good_loan) and have accuracy reaches 99%. Apart from that, ROC AUC has a score of **1.0** which shows the model's ability to differentiate between classes very well.

##### Apart from that, to identify whether the model predicted correctly or not, a false negative analysis was carried out with the results showing that there was no false negative data that could be analyzed so it can be said that the model very well identified bad loans.

##### The cross-validation value reaches 1.0, indicating that the model has consistent high performance in several data subsets.
"""